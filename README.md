# Simple LangChain RAG Pipeline â€“ Data Loading, Transformation & Embeddings

This notebook demonstrates a **simple yet effective RAG (Retrieval-Augmented Generation) pipeline** using [LangChain](https://www.langchain.com/). It walks through the full lifecycle of:

1. Ingesting data from **local text**, **web pages**, and **PDFs**
2. Transforming documents using chunking
3. Creating embeddings using **Hugging Face**
4. Storing them in vector stores like **Chroma** and **FAISS**
5. Performing semantic search queries on the indexed data

---

## ğŸ“ Pipeline Overview

### âœ… Step 1: Data Ingestion

We load data using different **LangChain loaders**:

- ğŸ“„ `TextLoader` â€“ Load from `.txt` files (`speech.txt`)
- ğŸŒ `WebBaseLoader` â€“ Load from a blog page (e.g., [Lilian Weng's blog](https://lilianweng.github.io/posts/2023-06-23-agent/)) with `BeautifulSoup` filtering
- ğŸ“š `PyPDFLoader` â€“ Load from PDF documents like `Colon.pdf`

### âœ… Step 2: Data Transformation

We split large text into manageable chunks using:

```python
RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)
````

This is essential for effective embedding and search performance.

### âœ… Step 3: Vector Embedding

We use Hugging Face embeddings via:

```python
HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
```

Other alternatives (commented out):

* `OpenAIEmbeddings`
* `OllamaEmbeddings`

### âœ… Step 4: Vector Stores

We tested two vector store implementations:

* ğŸ§  **Chroma**

```python
db1 = Chroma.from_documents(documents, embedding_model)
```

* ğŸ“¦ **FAISS**

```python
db2 = FAISS.from_documents(documents[:30], embedding_model)
```

Both support similarity search based on vector embeddings.

### âœ… Step 5: Semantic Search (Querying)

Perform a similarity search over the stored vectors:

```python
query = "The choice of first-line treatment in CRC follows"
results = db.similarity_search(query)
print(results[0].page_content)
```

---

## ğŸ›  Environment Setup

```bash
pip install -U langchain chromadb faiss-cpu beautifulsoup4 sentence-transformers python-dotenv
```

Also ensure:

* You have the `.env` file with your API keys (if needed).
* You have the `Colon.pdf` and `speech.txt` files in your working directory.

---

## ğŸ“‚ File Structure
.
â”œâ”€â”€ speech.txt                # Sample text file
â”œâ”€â”€ Colon.pdf                 # Sample PDF document
â”œâ”€â”€ .env                      # API keys and configuration
â”œâ”€â”€ simpleRAG.ipynb            # Main LangChain pipeline script
â””â”€â”€ README.md

## ğŸ“Œ Key Concepts Learned

* ğŸ“‚ Multiple data loading techniques: local files, web scraping, PDFs
* âœ‚ï¸ Efficient text chunking for RAG
* ğŸ§¬ Embedding text with sentence-transformers
* ğŸ“š Building vector stores with Chroma & FAISS
* ğŸ” Semantic search with natural language queries

---

## ğŸ“š Next Steps

* Add memory or context windows for QA systems
* Use `RetrievalQA` with LLMs for true RAG workflows
* Serve as API with `LangServe` or `FastAPI`
* Integrate with a chatbot UI for conversational RAG

---

## ğŸ™Œ Credits

* [LangChain Docs](https://docs.langchain.com/)
* [Sentence Transformers](https://www.sbert.net/)
* [ChromaDB](https://www.trychroma.com/)
* [FAISS by Facebook AI](https://github.com/facebookresearch/faiss)

---

## ğŸ§  Letâ€™s Build Smarter Retrieval Systems Together!
